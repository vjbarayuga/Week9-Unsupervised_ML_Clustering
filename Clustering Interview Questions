1. When would you use K-Means cluster and when would you use hierarchical cluster?
A hierarchical clustering is a set of nested clusters that are arranged as a tree. K Means clustering is found to work well when the structure of the clusters is hyper spherical (like circle in 2D, sphere in 3D). Hierarchical clustering don't work as well as, k means when the shape of the clusters is hyper spherical.

2. K- means clustering a simply a division of the set of data objects into non-overlapping subsets (clusters) such that each data object is in exactly one subset). A hierarchical clustering is a set of nested clusters that are arranged as a tree.

3. Kmeans algorithm is an iterative algorithm that tries to partition the dataset into Kpre-defined distinct non-overlapping subgroups (clusters) where each data point belongs to only one group. ... The less variation we have within clusters, the more homogeneous (similar) the data points are within the same cluster.

4. Where Can I Apply K-Means? k-means can typically be applied to data that has a smaller number of dimensions, is numeric, and is continuous. think of a scenario in which you want to make groups of similar things from a randomly distributed collection of things; k-means is very suitable for such scenarios.

5. k-means has trouble clustering data where clusters are of varying sizes and density. To cluster such data, you need to generalize k-means as described in the Advantages section. Clustering outliers. Centroids can be dragged by outliers, or outliers might get their own cluster instead of being ignored.

6. K-means requires a number of clusters. ... Explanation: Hierarchical clustering requires a defined distance as well. 10. K-means is not deterministic and it also consists of number of iterations.

7. The main difference between supervised and unsupervised learning: Labeled data. The main distinction between the two approaches is the use of labeled datasets. To put it simply, supervised learning uses labeled input and output data, while an unsupervised learning algorithm does not.

8. k-means is an unsupervised clustering algorithm where grouping is done simply on the basis of data values. k-nearest neighbour is a supervised classification algorithm where grouping is done based on a prior class information.

9. K-means is a centroid-based or partition-based clustering algorithm.  This algorithm partitions all the points in the sample space into K groups of similarity. The similarity is usually measured using Euclidian Distance. 
DBScan is a density-based clustering algorithm. The key fact of this algorithm is that the neighbourhood of each point in a cluster which is within a given radius (R) must have a minimum number of points (M). This algorithm has proved extremely efficient in detecting outliers and handling noise.

10. How clustering works for multiple features?
Clustering: Is the attempt to define groups among a set of objects (people in our case). The goal is that objects belonging to the same group share some key characteristics. K-Means: Is an iterative algorithm in which each observation belongs to the cluster with the nearest mean (centroids).
